function [belief_sim, Usim,precision,vargout] = tapas_hgf_binary_simsuppression_beta(nitems,nreps,meansup,nsampling,parname,sdintrusion,nu,startprob,suppressiontype)
% Calculates the trajectories of the agent's representations under the HGF
%
% This function can be called in two ways:
%
% (1) tapas_hgf_binary(r, p)
%
%     where r is the structure generated by tapas_fitModel and p is the parameter vector in native space;
%
% (2) tapas_hgf_binary(r, ptrans, 'trans')
%
%     where r is the structure generated by tapas_fitModel, ptrans is the parameter vector in
%     transformed space, and 'trans' is a flag indicating this.
%
% --------------------------------------------------------------------------------------------------
% Copyright (C) 2012-2017 Christoph Mathys, TNU, UZH & ETHZ
%
% This file is part of the HGF toolbox, which is released under the terms of the GNU General Public
% Licence (GPL), version 3. You can redistribute it and/or modify it under the terms of the GPL
% (either version 3 or, at your option, any later version). For further details, see the file
% COPYING or <http://www.gnu.org/licenses/>.

c                   = tapas_hgf_binary_2lev_config;
p                   = c.priormus;
r.c_prc.n_levels 	= 3;
p                   = tapas_hgf_binary_transp(r, p);% Transform paramaters back to their native space


% Number of levels
try
    l = r.c_prc.n_levels;
catch
    l = (length(p)+1)/5;
    
    if l ~= floor(l)
        error('tapas:hgf:UndetNumLevels', 'Cannot determine number of levels');
    end
end

% Unpack parameters
mu_0 = p(1:l);
sa_0 = p(l+1:2*l);
rho  = p(2*l+1:3*l);
ka   = p(3*l+1:4*l-1);
om   = p(4*l:5*l-2);
th   = exp(p(5*l-1));

% settings
n               = nitems*nreps;% Number of trials (including prior)
t               = ones(n,1);


% sampling parameter space
if nitems > 1
    rowidx = 1;
elseif nitems == 1
    rowidx = 2;
end

% gaussian or uniform draw ?
draw = 1;

% with truncated normal distribution ?
trunc = 0;

for par = 1:length(parname.idx)
    
    if draw ==1
        priorsd     = sqrt(parname.prior_var(rowidx,par)); % see drawn from a Gaussian with prior sd (tapas_sampleModel.m)
        priormean   = parname.prior_mean(rowidx,par);
        
        if trunc == 1
            minmax  = [parname.prior_min(rowidx,par) parname.prior_max(rowidx,par)];
        else
            minmax  = [-inf inf];
        end
        % truncated normal distribution with lower/upper limits to match
        % subject data
        
        samp_par = [];
        for i = 1:nsampling
            ok = 0;
            while ok~=1
                pval        = priormean+randn(1)*priorsd;
                if pval>minmax(1) & pval<minmax(2)
                    samp_par = [samp_par;pval];
                    ok = 1;
                    break;
                end
            end
        end
    elseif draw == 2
        a           = parname.prior_min(rowidx,par);
        b           = parname.prior_max(rowidx,par);
        samp_par        = unifrnd(a,b,[1 nsampling]);
    end
    pname       = sprintf('%s_sampling',parname.name{par});
    eval(sprintf('%s=samp_par;',pname))
    vargout{par} = eval(pname);
end

% suppression function
if strcmp(suppressiontype,'scal')
    supfun = @(a,b) a*b;
elseif  strcmp(suppressiontype,'sub')
    supfun = @(a,b) a-b;
end

belief_sim  = [];
Usim        = [];


suppressionfactor = meansup;


for i = 1:nsampling
    
    
    
    % update parameters
    om(2) = om_sampling(i);
    
    
    % Initialize updated quantities
    
    % Representations
    mu = NaN(n,l);
    pi = NaN(n,l);
    
    % Other quantities
    muhat = NaN(1,l);
    pihat = NaN(n,l);
    v     = NaN(n,l);
    w     = NaN(n,l-1);
    da    = NaN(n,l);
    
    % input
    u    = [];
%     u    = NaN(n,1);
  
    % Representation priors
    mu(1,1) = tapas_sgm(mu_0(1), 1);
    pi(1,1) = Inf;
    mu(1,2:end) = mu_0(2:end);
    pi(1,2:end) = 1./sa_0(2:end);
    
    
    muhat(1,2)     	= tapas_logit(startprob,1);muhat(1,3) = 0; % start with 0.5 prob of intrusion
    muhat(1,1)      = tapas_sgm(ka(1) *muhat(1,2), 1);
    
       
    % Infer input based on belief
    suppressedbel   = supfun(muhat(1,1),suppressionfactor);
    suppressedbel   = max([0.1 suppressedbel]);
    u(1)            = respsim(suppressedbel,nu,sdintrusion,u,nitems);
    mu(1,1)         = u(1);
    
    % Pass through representation update loop
    for k = 2:1:n
        
        
        
        %%%%%%%%%%%%%%%%%%%%%%
        % Effect of input u(k)
        %%%%%%%%%%%%%%%%%%%%%%
        
        % 2nd level prediction
        muhat(k,2) = mu(k-1,2) +t(k) *rho(2);
        
        
        % 1st level
        % ~~~~~~~~~
        % Prediction
        muhat(k,1) = tapas_sgm(ka(1) *muhat(k,2), 1);
      
        
        % Infer input based on suppressed belief
        suppressedbel  = supfun(muhat(k,1),suppressionfactor);
        suppressedbel  = max([0.1 suppressedbel]);
        belief         = [muhat(1:end-1,1);suppressedbel];
        u(k)           = respsim(belief,nu,sdintrusion,u,nitems);
        
        % Precision of prediction
        pihat(k,1) = 1/(muhat(k,1)*(1 -muhat(k,1)));
        
        % Updates
        pi(k,1) = Inf;
        mu(k,1) = u(k);
        
        % Prediction error
        da(k,1) = mu(k,1) -muhat(k,1);
        
        % 2nd level
        % ~~~~~~~~~
        % Prediction: see above
        
        % Precision of prediction
        pihat(k,2) = 1/(1/pi(k-1,2) +exp(ka(2) *mu(k-1,3) +om(2)));
        
        % Updates
        pi(k,2) = pihat(k,2) +ka(1)^2/pihat(k,1);
        mu(k,2) = muhat(k,2) +ka(1)/pi(k,2) *da(k,1);
        
        % Volatility prediction error
        da(k,2) = (1/pi(k,2) +(mu(k,2) -muhat(k,2))^2) *pihat(k,2) -1;
        
        if l > 3
            % Pass through higher levels
            % ~~~~~~~~~~~~~~~~~~~~~~~~~~
            for j = 3:l-1
                % Prediction
                muhat(k,j) = mu(k-1,j) +t(k) *rho(j);
                
                % Precision of prediction
                pihat(k,j) = 1/(1/pi(k-1,j) +t(k) *exp(ka(j) *mu(k-1,j+1) +om(j)));
                
                % Weighting factor
                v(k,j-1) = t(k) *exp(ka(j-1) *mu(k-1,j) +om(j-1));
                w(k,j-1) = v(k,j-1) *pihat(k,j-1);
                
                % Updates
                pi(k,j) = pihat(k,j) +1/2 *ka(j-1)^2 *w(k,j-1) *(w(k,j-1) +(2 *w(k,j-1) -1) *da(k,j-1));
                
                if pi(k,j) <= 0
                    error('tapas:hgf:NegPostPrec', 'Negative posterior precision. Parameters are in a region where model assumptions are violated.');
                end
                
                mu(k,j) = muhat(k,j) +1/2 *1/pi(k,j) *ka(j-1) *w(k,j-1) *da(k,j-1);
                
                % Volatility prediction error
                da(k,j) = (1/pi(k,j) +(mu(k,j) -muhat(k,j))^2) *pihat(k,j) -1;
            end
        end
        
        % Last level
        % ~~~~~~~~~~
        % Prediction
        muhat(k,l) = mu(k-1,l) +t(k) *rho(l);
        
        % Precision of prediction
        pihat(k,l) = 1/(1/pi(k-1,l) +t(k) *th);
        
        % Weighting factor
        v(k,l)   = t(k) *th;
        v(k,l-1) = t(k) *exp(ka(l-1) *mu(k-1,l) +om(l-1));
        w(k,l-1) = v(k,l-1) *pihat(k,l-1);
        
        % Updates
        pi(k,l) = pihat(k,l) +1/2 *ka(l-1)^2 *w(k,l-1) *(w(k,l-1) +(2 *w(k,l-1) -1) *da(k,l-1));
        
        if pi(k,l) <= 0
            error('tapas:hgf:NegPostPrec', 'Negative posterior precision. Parameters are in a region where model assumptions are violated.');
        end
        
        mu(k,l) = muhat(k,l) +1/2 *1/pi(k,l) *ka(l-1) *w(k,l-1) *da(k,l-1);
        
        % Volatility prediction error
        da(k,l) = (1/pi(k,l) +(mu(k,l) -muhat(k,l))^2) *pihat(k,l) -1;
        
        
    end
    precision(:,i)      = pihat(:,1);
    precision(1,i)      = pihat(2,1);
    belief_sim(:,i)     = muhat(:,1);
    Usim(:,i)           = u;
end

